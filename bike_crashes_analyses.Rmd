---
title: "Bike Crash Analyses"
author: "Elliott O'Brien"
date: "`R Sys.time()"
output: pdf_document
---

```{r setup, include = FALSE}
library('knitr')
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_libraries, include = FALSE}
library('tidyverse')
theme_set(theme_bw())
library('rnaturalearth')
library('rnaturalearthdata')

# Machine-learning and stats packages
library('caret')
library('ranger')
library('doParallel')

# default train control object
my_default_control <- trainControl(
  summaryFunction = multiClassSummary,
  classProbs = TRUE,
  savePredictions = TRUE
)
```

# Pre-Processing and Model Setup

Using the caret package, a pre-processing step will be used to remove near-zero
variance variables from the data set, to impute missing data, and to center and 
scale variables.  The trainControl object will be used to control the type of 
cross validation used to decrease overfitting.

Pre-Processing to be carried out:
* remove near-zero variance
* implement imputation (median, knn) for missing data
* center and scale to normalize data
* attempt principal components analysis (PCA) for feature reduction

As it can be seen in the table below, KNN does the best job imputing for various 
variables with missing data.

```{r pre_process}

# load cleaned-tidied data
bike_crashes_clean <- readRDS('./derived_data/bike_crashes_clean.rds')
bike_crash_dummies <- readRDS('./derived_data/bike_crash_dummies.rds')

########################
# Check Missing Values #
########################

# percent of missing data in each column
bike_crash_dummies %>%
  map(~ round(sum(is.na(.x)) / nrow(bike_crash_dummies) * 100, 1)) %>%
  as_tibble() %>%
  select(where(~.x > 10)) %>%
  kable(caption = 'Variables with more than 10% missing values')

################################################
# Split Data into training and testing dataset #
################################################
set.seed(24)
train_index <- createDataPartition(bike_crash_dummies$BikeInjuryDichot, p = .8, list=FALSE)
train_dat <- bike_crash_dummies[train_index,]
test_dat <- bike_crash_dummies[-train_index,]

# percent of missing data in each column
train_dat %>%
  map(~ round(sum(is.na(.x)) / nrow(train_dat) * 100, 1)) %>%
  as_tibble() %>%
  select(where(~.x > 10)) %>%
  kable(caption = 'training dataset vars with more than 10% missing')

test_dat %>%
  map(~ round(sum(is.na(.x)) / nrow(test_dat) * 100, 1)) %>%
  as_tibble() %>%
  select(where(~.x > 10)) %>%
  kable(caption = 'test dataset vars with more than 10% missing')

##################
# Pre-Processing #
##################

# attempt some imputations if possible
preproc_mdl <- preProcess(
  train_dat %>%
    select(-BikeInjuryDichot) %>% 
    as.data.frame,
  # centering and scaling done by knnImpute
  method = c('nzv', 'knnImpute')
)
preproc_mdl
# preproc_mdl$method

# run the preProcess predictions to create new dataset
bike_crashes_preProcessed <- predict(
  preproc_mdl,
  train_dat %>% as.data.frame
)
bike_crashes_preProcessed %>% glimpse()

# convert the BikeInjuryDichot variable from numeric to a factor that is
# variable name friendly
bike_crashes_preProcessed <-
  bike_crashes_preProcessed %>%
    mutate(
      BikeInjuryDichot = factor(
        if_else(BikeInjuryDichot == 1, 'Serious', 'Non.Serious'), 
        levels = c('Serious', 'Non.Serious')
      )
    )

test_dat <-
  test_dat %>%
    mutate(
      BikeInjuryDichot = factor(
        if_else(BikeInjuryDichot == 1, 'Serious', 'Non.Serious'), 
        levels = c('Serious', 'Non.Serious')
      )
    )

########################
# Check Missing Values #
########################

# percent of missing data in each column
bike_crashes_preProcessed %>%
  map(~ round(sum(is.na(.x)) / nrow(bike_crashes_preProcessed) * 100, 1)) %>%
  as_tibble() %>%
  select(where(~.x > 10))

## all variables have been imputed, with no missing values after KNN imputation.

# Serious Injuries are rare events, consider using down/up sampling
bike_crashes_preProcessed %>% 
  count(BikeInjuryDichot) %>% 
  mutate(pct = n / sum(n) * 100) %>%
  kable(caption = 'preprocessed training data class summary')

test_dat %>% 
  count(BikeInjuryDichot) %>% 
  mutate(pct = n / sum(n) * 100) %>%
  kable(caption = 'test data data class summary')
```

## Binomial Logistic-Regression 

```{r}
# cross validation methods
binomial_control <- trainControl(
  summaryFunction = twoClassSummary,
  classProbs = TRUE,
  savePredictions = TRUE,
  sampling = 'up',
  method = 'repeatedcv',
  repeats = 5
)

set.seed(42)

# Model using preprocessed features
cl <- makeCluster(7)
registerDoParallel(cl)

binom_mdl <- train(
  BikeInjuryDichot ~ .,
  data = bike_crashes_preProcessed %>%
    select(-AmbulanceR.Yes),
  method = 'glmnet',
  family = 'binomial',
  na.action = na.omit,
  trControl = binomial_control,
  tuneLenth = 20
)
stopCluster(cl)

# Model using principal components
cl <- makeCluster(7)
registerDoParallel(cl)

binom_PCA_mdl <- train(
  BikeInjuryDichot ~ .,
  data = bike_crashes_preProcessed %>%
    select(-AmbulanceR.Yes),
  method = 'glmnet',
  family = 'binomial',
  preProcess = c('pca'),
  na.action = na.omit,
  trControl = binomial_control,
  tuneLength = 20
)
stopCluster(cl)

###############
# Predictions #
###############

binom_mdl_pred <- predict(binom_mdl, newdata = test_dat, type = 'prob')

binom_mdl_pred <- binom_mdl_pred %>%
  mutate(
    pred1 = factor(if_else(Non.Serious < .9999, 'Serious', 'Non.Serious'), levels = c('Serious', 'Non.Serious')),
    pred2 = factor(if_else(Non.Serious < .999, 'Serious', 'Non.Serious'), levels = c('Serious', 'Non.Serious')),
    pred3 = factor(if_else(Non.Serious < .99, 'Serious', 'Non.Serious'), levels = c('Serious', 'Non.Serious'))
  )

confusionMatrix(
  binom_mdl_pred$pred1,
  test_dat[complete.cases(test_dat),]$BikeInjuryDichot
)

confusionMatrix(
  binom_mdl_pred$pred2,
  test_dat[complete.cases(test_dat),]$BikeInjuryDichot
)

confusionMatrix(
  binom_mdl_pred$pred3,
  test_dat[complete.cases(test_dat),]$BikeInjuryDichot
)

# PCA variables missing since partitioning was done before PCA
binom_PCA_mdl_pred <- predict(binom_PCA_mdl, newdata = test_dat, type = 'prob')

binom_PCA_mdl_pred <- binom_PCA_mdl_pred %>%
  mutate(
    pred1 = factor(if_else(Non.Serious < .9999, 'Serious', 'Non.Serious'), levels = c('Serious', 'Non.Serious')),
    pred2 = factor(if_else(Non.Serious < .999, 'Serious', 'Non.Serious'), levels = c('Serious', 'Non.Serious')),
    pred3 = factor(if_else(Non.Serious < .99, 'Serious', 'Non.Serious'), levels = c('Serious', 'Non.Serious'))
  )

confusionMatrix(
  binom_PCA_mdl_pred$pred1,
  test_dat[complete.cases(test_dat),]$BikeInjuryDichot
)

confusionMatrix(
  binom_PCA_mdl_pred$pred2,
  test_dat[complete.cases(test_dat),]$BikeInjuryDichot
)

confusionMatrix(
  binom_PCA_mdl_pred$pred3,
  test_dat[complete.cases(test_dat),]$BikeInjuryDichot
)
```

## Non-linear Classifcation Models (Random Forests)

```{r}

# Cross-Validation Methods
binomial_control <- trainControl(
  summaryFunction = twoClassSummary,
  classProbs = TRUE,
  savePredictions = TRUE,
  # # balance the response classes
  sampling = 'up',
  method = 'repeatedcv',
  repeats = 3
)

set.seed(42)

# Parallel Coding (comment out if not using)
cl <- makeCluster(7)
registerDoParallel(cl)
# serious injury is a rare event, let's use weights in resampling

rf_mdl <- train(
  BikeInjuryDichot ~ .,
  data = bike_crashes_preProcessed %>% 
    select(-AmbulanceR.Yes),
  method = 'ranger',
  trControl = binomial_control
)
stopCluster(cl)

# Predictions
rf_mdl_pred <- predict(rf_mdl, newdata = test_dat, type = 'prob')
confusionMatrix(
  rf_mdl_pred,
  test_dat[complete.cases(test_dat),]$BikeInjuryDichot
)

rf_mdl_pred <- rf_mdl_pred %>%
  mutate(
    pred1 = factor(if_else(Serious > .4475, 'Serious', 'Non.Serious'), levels = c('Serious', 'Non.Serious')),
    pred2 = factor(if_else(Serious > .45, 'Serious', 'Non.Serious'), levels = c('Serious', 'Non.Serious')),
    pred3 = factor(if_else(Serious > .4525, 'Serious', 'Non.Serious'), levels = c('Serious', 'Non.Serious'))
  )

confusionMatrix(
  rf_mdl_pred$pred1,
  test_dat[complete.cases(test_dat),]$BikeInjuryDichot
)

confusionMatrix(
  rf_mdl_pred$pred2,
  test_dat[complete.cases(test_dat),]$BikeInjuryDichot
)

confusionMatrix(
  rf_mdl_pred$pred3,
  test_dat[complete.cases(test_dat),]$BikeInjuryDichot
)
```
